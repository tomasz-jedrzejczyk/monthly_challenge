Flexibility: 
This is the ability of a system to be utilised in situations that were not included in the initial system requirements
Adaptability: 
This refers to the ease with which a system can be modified for new situations, such as migrating to different hardware or coping with changing operational environments
Importance in AI Systems:
Coping with new operational environments where the system is deployed globally
Adapting to new situations, such as variations in power sources
Determining when to change behaviour, such as a vehicle adjusting its braking automatically upon detecting wet roads
Self-learning systems are specifically expected to demonstrate both flexibility and adaptability to improve without constant external updates
Requirements and Acceptance Criteria:
Detailed Parameters- Requirements should include details of all environmental changes the system is expected to adapt to, such as specific temperature or humidity ranges
Constraints- Specifications must set limits on the time and resources the system (for flexibility) or humans (for adaptability) may use to adjust
Testing Criteria- Acceptance testing for adaptability involves checking if the system functions correctly and meets non-functional requirements after a change. For flexibility, testers consider how the system copes in contexts outside initial specs and the resources consumed to manage that new context
Documentation and Testing Challenges:
User Interfaces- When AI is used for interfaces (like computer vision), it must show increased flexibility; however, this makes it difficult to identify and document all possible interaction ways
Documentation as Test Basis- To test these qualities, developers must provide documentation regarding the operating environment, the source of input data, and the intended adaptation process
Simulation- Because defining test environments for undefined changes is difficult, testers often require imagination and virtual environments that can build in a level of randomness or uncertainty

Autonomy:
Capability of a system to operate for prolonged periods without human oversight or control
The Relationship Between AI and Autonomy:
AI as an Enabler- "Smart" or "intelligent" autonomous systems typically utilise AI components to perform complex tasks
Practical Limitations- The sources distinguish between the theoretical concept of a "fully autonomous" system—which would be entirely independent—and the reality of implementation where full autonomy is often not desired
Requirements and Specification
Operational Duration: Requirements must define the length of time a system is expected to perform satisfactorily without any human interference
Ceding Control: It is critical to identify the specific events or conditions under which the system must relinquish control and return it to a human operator
Operational Envelope: Specifications should define the "envelope" or environment in which the system is expected to remain fully autonomous
Testing and Acceptance Criteria
Requesting Intervention: Testers must verify if the system correctly asks for assistance when it exceeds its limits or when the environment changes
Unnecessary Requests: The system should be tested to ensure it does not unnecessarily interrupt its autonomous operation to ask for human help when it should be capable of continuing
Resistance to Persuasion: Acceptance criteria include checking whether a system can be "persuaded" (incorrectly triggered) to request intervention when it is intended to be independent
Techniques: Boundary Value Analysis can be applied to the operating environment to create the specific conditions needed to test these decision-making thresholds. Virtual test environments are often used for these tests, especially for dangerous or extreme scenarios

Evolution
Capability of a system to improve itself in response to changing external constraints. It is considered a vital characteristic for self-learning systems, which must incorporate evolution to be successful in dynamic environments
Forms of Managed Change
Internal Decisions: The system learns from its own decisions and its interactions with the environment.
Environmental Adaption: The system learns from changes in its operational environment. Ideally, the system evolves to increase its efficiency and effectiveness in both of these cases
Constraints and Safety
Preventing Unwanted Traits: Evolution must be limited to prevent the system from developing unwanted or harmful characteristics.
Requirement Alignment: Any improvement or change made by the system must continue to meet the initial system requirements and constraints.
Human Values: The evolution process must remain aligned with human values. For systems that interact physically with people, management is required to ensure that self-directed changes do not become dangerous
Specification and Testing Challenges
Lack of Documentation: System changes driven by self-learning are rarely documented by the system itself, which can cause regression tests to fail unless they are designed to be "future-proofed".
Predicting Improvements: It is challenging to determine if a system should always be expected to improve or if there is a quantified minimum improvement required.
Acceptance Criteria: To verify evolution, testers must check how well the system learns from its own experience and how it handles changes in the profile of data, often referred to as concept drift