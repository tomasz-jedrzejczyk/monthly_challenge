What is AI?
Artificial Intelligence is defined as the capability of an engineered system to acquire, process, and apply knowledge and skills.

What is AI Effect?
Describes how the definition of AI changes as technology advances.

Categorisation - AI types:
Narrow AI (Week AI)
Systems programmed for a specific task with limited context, such as spam filters, chatbots, or voice assistants.
General AI (Strong AI)
Hypothetical systems with human-like cognitive abilities across multiple domains.
Super AI
Conceptual systems that exceed human intelligence. The transition from General to Super AI is known as the Technological Singularity.

AI-Based vs Conventional Systems
Conventional Systems
Use imperative programming where humans write the code (if-then-else) to transform inputs into outputs, making the logic relatively easy to understand.
AI-Based Systems
Use Machine Learning (ML) to identify patterns in data to determine future reactions. This often makes the decision-making process less transparent to humans.

AI Technology Categories
Fuzzy Logic
A type of logic based on the concept of partial truth, where certainty factors range between 0 and 1, rather than being strictly binary
Search Algorithms
These systematically explore a subset of all possible states or structures until a specific goal state is reached.
Reasoning Technique
These technologies generate conclusions from available information using logical processes
-Rule engines: Set of rules that determines which specific actions should occur once certain conditions have been satisfied.
-Deductive classifiers: Classifier that is based on the application of inference and logic to input data.
-Case-based reasoning: Solving new problems based on similar past cases.
-Procedural reasoning: AI technology used for constructing real-time reasoning systems.
Machine Learning (ML) Techniques
Involving computational techniques that enable systems to learn from data or experience.
-Neural networks: Uses computational techniques to enable systems to learn from data or experience rather than following explicitly programmed imperative rules.
    *Deep Learning (DL): Specific category of machine learning that utilises Deep Neural Networks (DNN), which are defined by having multiple hidden layers of neurons.
      Layers and Neurons: A neural network consists of nodes called neurons organised into three types of layers: 
        Input layer that receives data,
        Output layer that produces the final prediction, 
        Hidden layers in between
    *Perceptrons: The simplest form is the single-layer perceptron, which contains only one layer and one neuron.
    *Weights and Biases: Each connection between neurons has an associated weight, while each individual neuron has a bias. These are internal variables that change as the network learns.
    *Activation Values: A neuron's output, calculated by an activation function.
-Support Vector Machines (SVM): mathematical technique in which data points are viewed as vectors in a multi-dimensional space, which are then separated by a hyperplane to allow for classification or regression.
-Decision trees and Random forests:
  *A decision tree is defined as a tree-like model where each node represents a specific decision and the branches represent the potential outcomes of those decisions
  *A random forest is an ensemble ML technology used for tasks such as classification and regression. It operates by constructing and running many individual decision trees simultaneously
-Bayesian models: operates by considering "before and after" probability distributions as the parameters of the statistical model.
-Clustering and Association algorithma: ability to group data points based on inherent similarities or common characteristics.
-Linear and Logistic regression:
  *Linear Regression is used for predicting continuous numerical values.
  *Logistic Regression is used for predicting categorical outputs, mostly binary classification.
-Genetic algorithms: population-based evolutionary optimization technique inspired by the principles of natural selection and genetics. It works by iteratively evolving a population of candidate solutions using biologically motivated operators such as selection, crossover and mutation to find optimal or near-optimal solutions to complex problems where traditional optimization techniques are ineffective.

Frameworks and Hardware
AI development frameworks are specialised tools and libraries that support the creation, training, and deployment of ML models. They handle various activities, including data preparation, algorithm selection, and the compilation of models to run on specific processors:
-TensorFlow: An open-source Google framework based on data flow graphs designed for scalable machine learning
-PyTorch: Operated by Facebook, this ML library is widely used for Natural Language Processing (NLP) and image processing
-Keras: A high-level Python API that can run on top of other toolkits like TensorFlow
-scikit-learn: A popular open-source library specifically for the Python programming language
-Specialised Toolkits: Amazon utilizes Apache MxNet for AWS, while Microsoft provides the Cognitive Toolkit (CNTK)
Hardware for AI prioritises massively parallel (concurrent) processing and the ability to work with large data structures for matrix multiplication
-Low-Precision Arithmetic: Probabilistic AI systems do not require exact calculations, so they often use 8-bit instead of 32-bit computation to increase speed and lower energy consumption
-Parallelism: Neural networks require thousands of simultaneous calculations, making hardware with high core counts essential
Processor Types
-GPUs (Graphical Processing Units): Originally designed for graphics, GPUs have thousands of cores and typically outperform CPUs in ML pattern recognition tasks
-AI-Specific Processors (ASICs/SoC): Custom hardware like Google’s TPU (Tensor Processing Unit), Intel’s Nervana, or Mobileye’s EyeQ are designed for high-performance data management and in-memory processing
-Neuromorphic Processors: A new generation of hardware currently under development that attempts to mimic biological neurons rather than following the traditional von Neumann architecture
-raining vs. Deployment: It is common to train models in the cloud using high-power hardware and then deploy the model to edge computing devices (like smartphones using Apple’s Bionic or Huawei’s Kirin chips) for operational use